{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8235800,
          "sourceType": "datasetVersion",
          "datasetId": 4884825
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Distilbert for MELD",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'meld-text-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4884825%2F8235800%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240426%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240426T114759Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D56a208b6c5bd667513cdaef2cf95f8de77642084037f56b7c351cf6f3b7b4883935d4fc21bb49695a56f4d95c123fe1802fe7da1997268d4ec8559526182a13b358a8552acff27cc2014beb8f53a61e255414f3628bbb68817dc9b2dcd3f532fdb439c6001d8bc7524522dd246bea37b313d15ce4e74ec3c77dfb2e2200cb556484c7f5e71f7bcf47f6da9d54d4268a9521cb53bfd811fc8167cb7c5f4143dcd96b456548ec416e3cca6df3e27d3680b9b23766bb4ed1b89e9af594ecc35d59ed6a39c941ab52da5609c3bfcde3ae7398ac1a7d2ddb59bde327b76c67631041ee042fc06e20ecdb882592788e13434c4376eaf4edc86831474d33c369463e549'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "TFs6fXb6QSO4"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "\n",
        "label_dict= {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n",
        "def f1_score_func(preds,labels):\n",
        "    preds_flat=np.argmax(preds,axis=1).flatten()\n",
        "    labels_flat=labels.flatten()\n",
        "    return f1_score(labels_flat,preds_flat,average=\"weighted\")\n",
        "\n",
        "def accuracy_per_class(preds,labels):\n",
        "    label_dict_inverse={v:k for k, v in label_dict.items()}\n",
        "    preds_flat=np.argmax(preds,axis=1).flatten()\n",
        "    labels_flat=labels.flatten()\n",
        "    totalacc=0\n",
        "    tot=0\n",
        "    for label in np.unique(labels_flat):\n",
        "        y_preds=preds_flat[labels_flat==label]\n",
        "        y_true=labels_flat[labels_flat==label]\n",
        "        totalacc+=len(y_preds[y_preds == label])\n",
        "        tot+=len(y_true)\n",
        "        print(f'Class: {label_dict_inverse[label]}')\n",
        "        print(f'Accuracy: {len(y_preds[y_preds == label])}/{len(y_true)}\\n')\n",
        "    print(\"Acc=\",totalacc/tot)"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-26T10:24:50.168446Z",
          "iopub.execute_input": "2024-04-26T10:24:50.168791Z",
          "iopub.status.idle": "2024-04-26T10:24:54.83816Z",
          "shell.execute_reply.started": "2024-04-26T10:24:50.168761Z",
          "shell.execute_reply": "2024-04-26T10:24:54.837319Z"
        },
        "trusted": true,
        "id": "yOKGXVGfQSO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:40:24.139569Z",
          "iopub.execute_input": "2024-04-26T10:40:24.13997Z",
          "iopub.status.idle": "2024-04-26T10:40:24.154795Z",
          "shell.execute_reply.started": "2024-04-26T10:40:24.139942Z",
          "shell.execute_reply": "2024-04-26T10:40:24.154045Z"
        },
        "trusted": true,
        "id": "DQ4Sj1WYQSO9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed and device\n",
        "seed_val = 994\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "device = torch.device(\"cuda\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:40:41.659527Z",
          "iopub.execute_input": "2024-04-26T10:40:41.660286Z",
          "iopub.status.idle": "2024-04-26T10:40:41.668115Z",
          "shell.execute_reply.started": "2024-04-26T10:40:41.660255Z",
          "shell.execute_reply": "2024-04-26T10:40:41.667295Z"
        },
        "trusted": true,
        "id": "q-RKlFSDQSO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define hyperparameters\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "learning_rate = 5e-5\n",
        "warmup_proportion = 0.1  # Percentage of training steps for warmup\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:40:55.151758Z",
          "iopub.execute_input": "2024-04-26T10:40:55.152488Z",
          "iopub.status.idle": "2024-04-26T10:40:55.156735Z",
          "shell.execute_reply.started": "2024-04-26T10:40:55.152458Z",
          "shell.execute_reply": "2024-04-26T10:40:55.155799Z"
        },
        "trusted": true,
        "id": "ZE4Z3vCsQSO-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = pd.read_csv(\"/kaggle/input/meld-text-data/train_sent_emo.csv\")\n",
        "dev_data = pd.read_csv(\"/kaggle/input/meld-text-data/dev_sent_emo (1).csv\")\n",
        "test_data = pd.read_csv(\"/kaggle/input/meld-text-data/test_sent_emo.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:42:08.450814Z",
          "iopub.execute_input": "2024-04-26T10:42:08.451214Z",
          "iopub.status.idle": "2024-04-26T10:42:08.513761Z",
          "shell.execute_reply.started": "2024-04-26T10:42:08.451183Z",
          "shell.execute_reply": "2024-04-26T10:42:08.512989Z"
        },
        "trusted": true,
        "id": "cYCndPB1QSO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define label dictionary\n",
        "label_dict = {label: i for i, label in enumerate(train_data['Emotion'].unique())}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:42:26.593825Z",
          "iopub.execute_input": "2024-04-26T10:42:26.594505Z",
          "iopub.status.idle": "2024-04-26T10:42:26.602343Z",
          "shell.execute_reply.started": "2024-04-26T10:42:26.594475Z",
          "shell.execute_reply": "2024-04-26T10:42:26.601312Z"
        },
        "trusted": true,
        "id": "9zVsRVmMQSO_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_dict"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:42:33.332453Z",
          "iopub.execute_input": "2024-04-26T10:42:33.333248Z",
          "iopub.status.idle": "2024-04-26T10:42:33.342436Z",
          "shell.execute_reply.started": "2024-04-26T10:42:33.333217Z",
          "shell.execute_reply": "2024-04-26T10:42:33.341565Z"
        },
        "trusted": true,
        "id": "XTMlV6dUQSO_",
        "outputId": "4b4ddf82-82e4-48a0-ff06-9cde948f3930"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'neutral': 0,\n 'surprise': 1,\n 'fear': 2,\n 'sadness': 3,\n 'joy': 4,\n 'disgust': 5,\n 'anger': 6}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace labels with numeric IDs\n",
        "train_data['Emotion'] = train_data['Emotion'].replace(label_dict)\n",
        "dev_data['Emotion'] = dev_data['Emotion'].replace(label_dict)\n",
        "test_data['Emotion'] = test_data['Emotion'].replace(label_dict)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:42:49.905448Z",
          "iopub.execute_input": "2024-04-26T10:42:49.905801Z",
          "iopub.status.idle": "2024-04-26T10:42:49.931852Z",
          "shell.execute_reply.started": "2024-04-26T10:42:49.905776Z",
          "shell.execute_reply": "2024-04-26T10:42:49.930846Z"
        },
        "trusted": true,
        "id": "NwdTYBywQSPB",
        "outputId": "e2520a19-8945-42ca-c785-ee03a6945a63"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/tmp/ipykernel_34/3461972530.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  train_data['Emotion'] = train_data['Emotion'].replace(label_dict)\n/tmp/ipykernel_34/3461972530.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  dev_data['Emotion'] = dev_data['Emotion'].replace(label_dict)\n/tmp/ipykernel_34/3461972530.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n  test_data['Emotion'] = test_data['Emotion'].replace(label_dict)\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get utterances\n",
        "utterances_train = train_data[\"Utterance\"].values\n",
        "utterances_dev = dev_data[\"Utterance\"].values\n",
        "utterances_test = test_data[\"Utterance\"].values\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:43:04.943888Z",
          "iopub.execute_input": "2024-04-26T10:43:04.944269Z",
          "iopub.status.idle": "2024-04-26T10:43:04.949732Z",
          "shell.execute_reply.started": "2024-04-26T10:43:04.944239Z",
          "shell.execute_reply": "2024-04-26T10:43:04.948763Z"
        },
        "trusted": true,
        "id": "tN3BHauBQSPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DistilBERT tokenizer\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:43:16.841436Z",
          "iopub.execute_input": "2024-04-26T10:43:16.842122Z",
          "iopub.status.idle": "2024-04-26T10:43:17.182004Z",
          "shell.execute_reply.started": "2024-04-26T10:43:16.842087Z",
          "shell.execute_reply": "2024-04-26T10:43:17.181148Z"
        },
        "trusted": true,
        "id": "bjv5ovuyQSPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:43:21.474891Z",
          "iopub.execute_input": "2024-04-26T10:43:21.475817Z",
          "iopub.status.idle": "2024-04-26T10:43:21.481428Z",
          "shell.execute_reply.started": "2024-04-26T10:43:21.475785Z",
          "shell.execute_reply": "2024-04-26T10:43:21.48055Z"
        },
        "trusted": true,
        "id": "8Y4uDNUJQSPD",
        "outputId": "e6135512-5b1b-4edf-f44f-d483c6483226"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DistilBertTokenizer(name_or_path='distilbert-base-uncased', vocab_size=30522, model_max_length=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t100: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t101: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t102: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n\t103: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize and prepare datasets\n",
        "encoded_inputs_train = tokenizer(list(utterances_train), padding=True, truncation=True, max_length=50, return_tensors='pt')\n",
        "encoded_inputs_dev = tokenizer(list(utterances_dev), padding=True, truncation=True, max_length=50, return_tensors='pt')\n",
        "encoded_inputs_test = tokenizer(list(utterances_test), padding=True, truncation=True, max_length=50, return_tensors='pt')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:43:33.159937Z",
          "iopub.execute_input": "2024-04-26T10:43:33.160803Z",
          "iopub.status.idle": "2024-04-26T10:43:38.608789Z",
          "shell.execute_reply.started": "2024-04-26T10:43:33.160772Z",
          "shell.execute_reply": "2024-04-26T10:43:38.607806Z"
        },
        "trusted": true,
        "id": "OIsejukgQSPD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_inputs_test"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:43:52.979621Z",
          "iopub.execute_input": "2024-04-26T10:43:52.980574Z",
          "iopub.status.idle": "2024-04-26T10:43:53.018284Z",
          "shell.execute_reply.started": "2024-04-26T10:43:52.980539Z",
          "shell.execute_reply": "2024-04-26T10:43:53.017291Z"
        },
        "trusted": true,
        "id": "HOD9FUxJQSPD",
        "outputId": "0d8331b6-356a-4216-a447-9a927cec17c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 18,
          "output_type": "execute_result",
          "data": {
            "text/plain": "{'input_ids': tensor([[ 101, 2339, 2079,  ...,    0,    0,    0],\n        [ 101, 2821, 1012,  ...,    0,    0,    0],\n        [ 101, 1061, 1005,  ...,    0,    0,    0],\n        ...,\n        [ 101, 1997, 2607,  ...,    0,    0,    0],\n        [ 101, 9018, 2017,  ...,    0,    0,    0],\n        [ 101, 1045, 2228,  ...,    0,    0,    0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        ...,\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0],\n        [1, 1, 1,  ..., 0, 0, 0]])}"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_train = encoded_inputs_train[\"input_ids\"]\n",
        "attention_mask_train = encoded_inputs_train[\"attention_mask\"]\n",
        "labels_train = torch.tensor(train_data['Emotion'].values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:44:10.986546Z",
          "iopub.execute_input": "2024-04-26T10:44:10.987188Z",
          "iopub.status.idle": "2024-04-26T10:44:10.998526Z",
          "shell.execute_reply.started": "2024-04-26T10:44:10.987157Z",
          "shell.execute_reply": "2024-04-26T10:44:10.997396Z"
        },
        "trusted": true,
        "id": "_QKSQXU9QSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_dev = encoded_inputs_dev[\"input_ids\"]\n",
        "attention_mask_dev = encoded_inputs_dev[\"attention_mask\"]\n",
        "labels_dev = torch.tensor(dev_data['Emotion'].values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:44:22.034261Z",
          "iopub.execute_input": "2024-04-26T10:44:22.035128Z",
          "iopub.status.idle": "2024-04-26T10:44:22.039625Z",
          "shell.execute_reply.started": "2024-04-26T10:44:22.035095Z",
          "shell.execute_reply": "2024-04-26T10:44:22.038727Z"
        },
        "trusted": true,
        "id": "fxByk8I0QSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_test = encoded_inputs_test[\"input_ids\"]\n",
        "attention_mask_test = encoded_inputs_test[\"attention_mask\"]\n",
        "labels_test = torch.tensor(test_data['Emotion'].values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:45:02.698299Z",
          "iopub.execute_input": "2024-04-26T10:45:02.698665Z",
          "iopub.status.idle": "2024-04-26T10:45:02.703763Z",
          "shell.execute_reply.started": "2024-04-26T10:45:02.698639Z",
          "shell.execute_reply": "2024-04-26T10:45:02.702876Z"
        },
        "trusted": true,
        "id": "xJ5Ig8DpQSPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "dataset_train = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n",
        "dataset_dev = TensorDataset(input_ids_dev, attention_mask_dev, labels_dev)\n",
        "dataset_test = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:45:14.635877Z",
          "iopub.execute_input": "2024-04-26T10:45:14.636777Z",
          "iopub.status.idle": "2024-04-26T10:45:14.641554Z",
          "shell.execute_reply.started": "2024-04-26T10:45:14.636744Z",
          "shell.execute_reply": "2024-04-26T10:45:14.640406Z"
        },
        "trusted": true,
        "id": "W1URZIO6QSPF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:45:37.050665Z",
          "iopub.execute_input": "2024-04-26T10:45:37.051113Z",
          "iopub.status.idle": "2024-04-26T10:45:37.058339Z",
          "shell.execute_reply.started": "2024-04-26T10:45:37.051078Z",
          "shell.execute_reply": "2024-04-26T10:45:37.057064Z"
        },
        "trusted": true,
        "id": "oKquZOfuQSPF",
        "outputId": "a6ce7f81-020c-4c17-bb88-0f6c2b3eb247"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 23,
          "output_type": "execute_result",
          "data": {
            "text/plain": "device(type='cuda')"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize DistilBERT model for sequence classification\n",
        "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=len(label_dict))\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:45:40.327557Z",
          "iopub.execute_input": "2024-04-26T10:45:40.328316Z",
          "iopub.status.idle": "2024-04-26T10:45:48.660923Z",
          "shell.execute_reply.started": "2024-04-26T10:45:40.328283Z",
          "shell.execute_reply": "2024-04-26T10:45:48.659937Z"
        },
        "trusted": true,
        "id": "PA8S67JbQSPG",
        "outputId": "e4517b7c-66bb-4b27-af50-c7428e1160ce",
        "colab": {
          "referenced_widgets": [
            "9dc9098582c346ae8c5eec2886fd8b58"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9dc9098582c346ae8c5eec2886fd8b58"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "DistilBertForSequenceClassification(\n  (distilbert): DistilBertModel(\n    (embeddings): Embeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n      (position_embeddings): Embedding(512, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n    )\n    (transformer): Transformer(\n      (layer): ModuleList(\n        (0-5): 6 x TransformerBlock(\n          (attention): MultiHeadSelfAttention(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (q_lin): Linear(in_features=768, out_features=768, bias=True)\n            (k_lin): Linear(in_features=768, out_features=768, bias=True)\n            (v_lin): Linear(in_features=768, out_features=768, bias=True)\n            (out_lin): Linear(in_features=768, out_features=768, bias=True)\n          )\n          (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n          (ffn): FFN(\n            (dropout): Dropout(p=0.1, inplace=False)\n            (lin1): Linear(in_features=768, out_features=3072, bias=True)\n            (lin2): Linear(in_features=3072, out_features=768, bias=True)\n            (activation): GELUActivation()\n          )\n          (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n        )\n      )\n    )\n  )\n  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n  (dropout): Dropout(p=0.2, inplace=False)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True}\n",
        "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size, **kwargs)\n",
        "dataloader_dev = DataLoader(dataset_dev, sampler=SequentialSampler(dataset_dev), batch_size=batch_size, **kwargs)\n",
        "dataloader_test = DataLoader(dataset_test, sampler=SequentialSampler(dataset_test), batch_size=len(dataset_test), **kwargs)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:46:02.613607Z",
          "iopub.execute_input": "2024-04-26T10:46:02.614256Z",
          "iopub.status.idle": "2024-04-26T10:46:02.620372Z",
          "shell.execute_reply.started": "2024-04-26T10:46:02.614223Z",
          "shell.execute_reply": "2024-04-26T10:46:02.619384Z"
        },
        "trusted": true,
        "id": "tm4GwvQKQSPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set optimizer and learning rate scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=learning_rate, eps=1e-8)\n",
        "total_steps = len(dataloader_train) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=int(total_steps * warmup_proportion), num_training_steps=total_steps)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:46:12.582597Z",
          "iopub.execute_input": "2024-04-26T10:46:12.58297Z",
          "iopub.status.idle": "2024-04-26T10:46:12.593447Z",
          "shell.execute_reply.started": "2024-04-26T10:46:12.582945Z",
          "shell.execute_reply": "2024-04-26T10:46:12.592426Z"
        },
        "trusted": true,
        "id": "NGxySqg0QSPG",
        "outputId": "bde6e9ff-ded2-472b-9aa6-14afa1f03016"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate model\n",
        "def evaluate(dataloader):\n",
        "    model.eval()\n",
        "    predictions, true_vals = [], []\n",
        "\n",
        "    for batch in dataloader:\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        logits = outputs[1].detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "        predictions.append(logits)\n",
        "        true_vals.append(label_ids)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_vals = np.concatenate(true_vals, axis=0)\n",
        "    return predictions, true_vals"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:46:24.098369Z",
          "iopub.execute_input": "2024-04-26T10:46:24.098739Z",
          "iopub.status.idle": "2024-04-26T10:46:24.106342Z",
          "shell.execute_reply.started": "2024-04-26T10:46:24.098711Z",
          "shell.execute_reply": "2024-04-26T10:46:24.105405Z"
        },
        "trusted": true,
        "id": "OGIhcamWQSPH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training loop\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    progress_bar = tqdm(dataloader_train, desc=f\"Epoch {epoch}\", leave=False, disable=False)\n",
        "    for batch in progress_bar:\n",
        "        model.zero_grad()\n",
        "        batch = tuple(b.to(device) for b in batch)\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        progress_bar.set_postfix({'training loss': f\"{loss.item() / len(batch):.2f}\"})\n",
        "\n",
        "    # Save model after each epoch (optional)\n",
        "    torch.save(model.state_dict(), f\"./distilbert_finetuned_epoch{epoch}.model\")\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    predictions_dev, true_vals_dev = evaluate(dataloader_dev)\n",
        "    val_loss = total_loss / len(dataloader_dev)\n",
        "    val_f1 = f1_score(np.argmax(predictions_dev, axis=1), true_vals_dev, average='weighted')\n",
        "\n",
        "    tqdm.write(f\"Epoch {epoch}\")\n",
        "    tqdm.write(f\"Validation loss: {val_loss:.4f}\")\n",
        "    tqdm.write(f\"F1 Score (Weighted): {val_f1:.4f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:51:59.239707Z",
          "iopub.execute_input": "2024-04-26T10:51:59.240736Z",
          "iopub.status.idle": "2024-04-26T10:55:03.915944Z",
          "shell.execute_reply.started": "2024-04-26T10:51:59.240689Z",
          "shell.execute_reply": "2024-04-26T10:55:03.91476Z"
        },
        "trusted": true,
        "id": "JWDVkDO1QSPH",
        "outputId": "776a856d-cb0a-41b3-8e64-50b6ca98f086"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "                                                                              \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 1\nValidation loss: 2.4194\nF1 Score (Weighted): 0.6114\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                              \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 2\nValidation loss: 2.4249\nF1 Score (Weighted): 0.6114\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                              \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 3\nValidation loss: 2.3855\nF1 Score (Weighted): 0.6114\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                              \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 4\nValidation loss: 2.3985\nF1 Score (Weighted): 0.6114\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "                                                                              \r",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "Epoch 5\nValidation loss: 2.4193\nF1 Score (Weighted): 0.6114\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate on test set\n",
        "model.eval()\n",
        "predictions_test, true_vals_test = evaluate(dataloader_test)\n",
        "accuracy_per_class(predictions_test, true_vals_test)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T10:50:00.852748Z",
          "iopub.execute_input": "2024-04-26T10:50:00.853157Z",
          "iopub.status.idle": "2024-04-26T10:50:02.808904Z",
          "shell.execute_reply.started": "2024-04-26T10:50:00.853122Z",
          "shell.execute_reply": "2024-04-26T10:50:02.807727Z"
        },
        "trusted": true,
        "id": "1350FPgDQSPI",
        "outputId": "a790ece9-1b56-4378-e96f-dd2f36a84cbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Class: neutral\nAccuracy: 994/1256\n\nClass: surprise\nAccuracy: 160/281\n\nClass: fear\nAccuracy: 4/50\n\nClass: sadness\nAccuracy: 49/208\n\nClass: joy\nAccuracy: 225/402\n\nClass: disgust\nAccuracy: 17/68\n\nClass: anger\nAccuracy: 133/345\n\nAcc= 0.6061302681992338\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "# Save the final trained model\n",
        "torch.save(model.state_dict(), \"/kaggle/working/distilbert_finetuned_epoch5.model\")\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions_test, true_vals_test = evaluate(dataloader_test)\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(true_vals_test, np.argmax(predictions_test, axis=1))\n",
        "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
        "\n",
        "# Compute classification report\n",
        "target_names = [label for label in label_dict.keys()]\n",
        "print(classification_report(true_vals_test, np.argmax(predictions_test, axis=1), target_names=target_names))\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(true_vals_test, np.argmax(predictions_test, axis=1))\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Compute macro and micro F1 scores\n",
        "macro_f1 = f1_score(true_vals_test, np.argmax(predictions_test, axis=1), average='macro')\n",
        "micro_f1 = f1_score(true_vals_test, np.argmax(predictions_test, axis=1), average='micro')\n",
        "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
        "print(f\"Micro F1 Score: {micro_f1:.4f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T11:33:37.828875Z",
          "iopub.execute_input": "2024-04-26T11:33:37.829303Z",
          "iopub.status.idle": "2024-04-26T11:33:40.350863Z",
          "shell.execute_reply.started": "2024-04-26T11:33:37.829259Z",
          "shell.execute_reply": "2024-04-26T11:33:40.349646Z"
        },
        "trusted": true,
        "id": "8x3X9lJwQSPI",
        "outputId": "d315cc8f-5dc6-4af9-c039-a9d90b0c5328"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test Accuracy: 0.6061\n              precision    recall  f1-score   support\n\n     neutral       0.75      0.79      0.77      1256\n    surprise       0.47      0.57      0.52       281\n        fear       0.13      0.08      0.10        50\n     sadness       0.36      0.24      0.29       208\n         joy       0.53      0.56      0.54       402\n     disgust       0.35      0.25      0.29        68\n       anger       0.44      0.39      0.41       345\n\n    accuracy                           0.61      2610\n   macro avg       0.43      0.41      0.42      2610\nweighted avg       0.59      0.61      0.60      2610\n\nConfusion Matrix:\n[[994  62  14  39  86  13  48]\n [ 44 160   1   4  30   2  40]\n [ 16   7   4   9   5   1   8]\n [ 85  17   6  49  23   3  25]\n [ 93  30   2  12 225   3  37]\n [ 22   8   0   4   3  17  14]\n [ 76  53   4  18  52   9 133]]\nMacro F1 Score: 0.4169\nMicro F1 Score: 0.6061\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Load tokenizer and model\n",
        "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
        "model_path = \"/kaggle/working/distilbert_finetuned_epoch5.model\"\n",
        "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "\n",
        "# Function to predict emotion from user sentence\n",
        "def predict_emotion(user_sentence):\n",
        "    # Tokenize the input sentence\n",
        "    encoded_user_input = tokenizer.encode_plus(\n",
        "        user_sentence,\n",
        "        add_special_tokens=True,\n",
        "        max_length=50,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "\n",
        "    # Move input tensors to the appropriate device (e.g., CUDA if available)\n",
        "    input_ids = encoded_user_input['input_ids'].to(device)\n",
        "    attention_mask = encoded_user_input['attention_mask'].to(device)\n",
        "\n",
        "    # Pass the input tensors through the model to obtain predictions\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "\n",
        "    # Extract predicted class probabilities\n",
        "    probabilities = torch.softmax(outputs.logits, dim=1).squeeze().cpu().numpy()\n",
        "\n",
        "    # Determine the predicted class\n",
        "    predicted_class_idx = np.argmax(probabilities)\n",
        "    predicted_emotion = list(label_dict.keys())[list(label_dict.values()).index(predicted_class_idx)]\n",
        "\n",
        "    # Prepare output with emotion predictions and confidence scores\n",
        "    output = {}\n",
        "    output['predicted_emotion'] = predicted_emotion\n",
        "    output['confidence_scores'] = {label: prob for label, prob in zip(label_dict.keys(), probabilities)}\n",
        "\n",
        "    return output\n",
        "\n",
        "# Example user sentence\n",
        "user_sentence = \"I wish I was intelligent enough to do this project on my own.\"\n",
        "\n",
        "# Predict emotion from the user sentence\n",
        "result = predict_emotion(user_sentence)\n",
        "\n",
        "# Print the predicted emotion and confidence scores\n",
        "print(\"Predicted Emotion:\", result['predicted_emotion'])\n",
        "print(\"Confidence Scores:\")\n",
        "for label, score in result['confidence_scores'].items():\n",
        "    print(f\"{label}: {score:.4f}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T11:40:44.045579Z",
          "iopub.execute_input": "2024-04-26T11:40:44.04597Z",
          "iopub.status.idle": "2024-04-26T11:40:44.6095Z",
          "shell.execute_reply.started": "2024-04-26T11:40:44.045941Z",
          "shell.execute_reply": "2024-04-26T11:40:44.607917Z"
        },
        "trusted": true,
        "id": "DeV9jDswQSPJ",
        "outputId": "a197b822-c3c4-49dd-e8eb-6a257ca7680a"
      },
      "execution_count": null,
      "outputs": [
        {
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:398\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    397\u001b[0m     \u001b[38;5;66;03m# Load from URL or cache if already cached\u001b[39;00m\n\u001b[0;32m--> 398\u001b[0m     resolved_file \u001b[38;5;241m=\u001b[39m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_repo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    401\u001b[0m \u001b[43m        \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    403\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    405\u001b[0m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    406\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    407\u001b[0m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    408\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    409\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    410\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    411\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m GatedRepoError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:111\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m arg_name \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrepo_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m--> 111\u001b[0m     \u001b[43mvalidate_repo_id\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m arg_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m arg_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/huggingface_hub/utils/_validators.py:159\u001b[0m, in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m repo_id\u001b[38;5;241m.\u001b[39mcount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 159\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HFValidationError(\n\u001b[1;32m    160\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRepo id must be in the form \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrepo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnamespace/repo_name\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    161\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrepo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Use `repo_type` argument if needed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    162\u001b[0m     )\n\u001b[1;32m    164\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m REPO_ID_REGEX\u001b[38;5;241m.\u001b[39mmatch(repo_id):\n",
            "\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/kaggle/working/distilbert_finetuned_epoch5.model'. Use `repo_type` argument if needed.",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[42], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m model_save_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/kaggle/working/distilbert_finetuned_epoch5.model\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Load the fine-tuned DistilBERT model from the saved directory\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mDistilBertForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_save_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Set the device for inference\u001b[39;00m\n\u001b[1;32m     12\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/modeling_utils.py:2899\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m commit_hash \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2897\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(config, PretrainedConfig):\n\u001b[1;32m   2898\u001b[0m         \u001b[38;5;66;03m# We make a call to the config file first (which may be absent) to get the commit hash as soon as possible\u001b[39;00m\n\u001b[0;32m-> 2899\u001b[0m         resolved_config_file \u001b[38;5;241m=\u001b[39m \u001b[43mcached_file\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2900\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2901\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_NAME\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2902\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2903\u001b[0m \u001b[43m            \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[43m            \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2905\u001b[0m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2906\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2907\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2908\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2909\u001b[0m \u001b[43m            \u001b[49m\u001b[43msubfolder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubfolder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2910\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_gated_repo\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2911\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_missing_entries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2912\u001b[0m \u001b[43m            \u001b[49m\u001b[43m_raise_exceptions_for_connection_errors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2913\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2914\u001b[0m         commit_hash \u001b[38;5;241m=\u001b[39m extract_commit_hash(resolved_config_file, commit_hash)\n\u001b[1;32m   2915\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:462\u001b[0m, in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThere was a specific connection error when trying to load \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HFValidationError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 462\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(\n\u001b[1;32m    463\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncorrect path_or_model_id: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath_or_repo_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Please provide either the path to a local folder or the repo_id of a model on the Hub.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    464\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resolved_file\n",
            "\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/kaggle/working/distilbert_finetuned_epoch5.model'. Please provide either the path to a local folder or the repo_id of a model on the Hub."
          ],
          "ename": "OSError",
          "evalue": "Incorrect path_or_model_id: '/kaggle/working/distilbert_finetuned_epoch5.model'. Please provide either the path to a local folder or the repo_id of a model on the Hub.",
          "output_type": "error"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zr5ApGFgQSPK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}