{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8237522,
          "sourceType": "datasetVersion",
          "datasetId": 4886147
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "ALBERT for MELD",
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'meld-text:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4886147%2F8237522%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240426%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240426T150632Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D660c3b38fad08f4f33daecbedde14358745dfa50ef062334d2d03c72d99e137b03d74d2e2d68ee0a46d88aecd9153156c17fcc999cc43e2ce53d7e0461203cd51148b1415a3039633a49158c084e9d2297be860ce46097b5bb34e9b169ad54b15d9814efc054d87dc5217f20c05707ef8e857473543b7a41e7f9fb89b4305200a7fcefac8148c29494960896cfcc0c7d1a7982e843f45afe4ae78447651ed731abdd4b2eb25849edca06a0ed4767ee2c9099f3ed3d95d2248c85939233a045a0b5c58be2f2bb31b102fec77babbaa96a66cbd951c76a67c17b35126d46ff2a950405eff86e02a2af68ee071ff6eb37daf2104e2b5d78142c149c005624a3b9f9'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "1Holhvj98aPS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:08:23.200365Z",
          "iopub.execute_input": "2024-04-26T14:08:23.200697Z",
          "iopub.status.idle": "2024-04-26T14:08:24.227958Z",
          "shell.execute_reply.started": "2024-04-26T14:08:23.200672Z",
          "shell.execute_reply": "2024-04-26T14:08:24.226806Z"
        },
        "trusted": true,
        "id": "KkfrxAug8aPX",
        "outputId": "51f9d26b-c288-474d-f750-7151bbd0340e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Fri Apr 26 14:08:24 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   37C    P0              27W / 250W |      0MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|  No running processes found                                                           |\n+---------------------------------------------------------------------------------------+\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset, RandomSampler, SequentialSampler\n",
        "from transformers import AlbertTokenizer, AlbertForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-26T14:08:36.704114Z",
          "iopub.execute_input": "2024-04-26T14:08:36.704742Z",
          "iopub.status.idle": "2024-04-26T14:08:44.50849Z",
          "shell.execute_reply.started": "2024-04-26T14:08:36.704709Z",
          "shell.execute_reply": "2024-04-26T14:08:44.507701Z"
        },
        "trusted": true,
        "id": "icdpUwXV8aPZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed for reproducibility\n",
        "seed_val = 42\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:08:53.913687Z",
          "iopub.execute_input": "2024-04-26T14:08:53.91495Z",
          "iopub.status.idle": "2024-04-26T14:08:53.92169Z",
          "shell.execute_reply.started": "2024-04-26T14:08:53.914916Z",
          "shell.execute_reply": "2024-04-26T14:08:53.920931Z"
        },
        "trusted": true,
        "id": "lIatYku-8aPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data\n",
        "train_data = pd.read_csv(\"/kaggle/input/meld-text/train_sent_emo.csv\")\n",
        "dev_data = pd.read_csv(\"/kaggle/input/meld-text/dev_sent_emo.csv\")\n",
        "test_data = pd.read_csv(\"/kaggle/input/meld-text/test_sent_emo.csv\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:09:46.140373Z",
          "iopub.execute_input": "2024-04-26T14:09:46.141111Z",
          "iopub.status.idle": "2024-04-26T14:09:46.238434Z",
          "shell.execute_reply.started": "2024-04-26T14:09:46.141072Z",
          "shell.execute_reply": "2024-04-26T14:09:46.237593Z"
        },
        "trusted": true,
        "id": "RHhz_ouM8aPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Map emotion labels to integers\n",
        "label_dict = {'neutral': 0, 'surprise': 1, 'fear': 2, 'sadness': 3, 'joy': 4, 'disgust': 5, 'anger': 6}\n",
        "train_data['Emotion'] = train_data['Emotion'].map(label_dict)\n",
        "dev_data['Emotion'] = dev_data['Emotion'].map(label_dict)\n",
        "test_data['Emotion'] = test_data['Emotion'].map(label_dict)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:09:56.655621Z",
          "iopub.execute_input": "2024-04-26T14:09:56.655975Z",
          "iopub.status.idle": "2024-04-26T14:09:56.673565Z",
          "shell.execute_reply.started": "2024-04-26T14:09:56.655948Z",
          "shell.execute_reply": "2024-04-26T14:09:56.672607Z"
        },
        "trusted": true,
        "id": "Ad6yhcRE8aPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load ALBERT tokenizer\n",
        "tokenizer = AlbertTokenizer.from_pretrained('albert-base-v2')\n",
        "\n",
        "# Tokenize data\n",
        "def tokenize_data(data, tokenizer):\n",
        "    encoded_data = tokenizer.batch_encode_plus(\n",
        "        data,\n",
        "        add_special_tokens=True,\n",
        "        return_attention_mask=True,\n",
        "        padding=True,\n",
        "        max_length=50,\n",
        "        truncation=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    return encoded_data['input_ids'], encoded_data['attention_mask']"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:10:08.353478Z",
          "iopub.execute_input": "2024-04-26T14:10:08.353868Z",
          "iopub.status.idle": "2024-04-26T14:10:10.575075Z",
          "shell.execute_reply.started": "2024-04-26T14:10:08.353839Z",
          "shell.execute_reply": "2024-04-26T14:10:10.574074Z"
        },
        "trusted": true,
        "id": "E3ag0Asf8aPb",
        "outputId": "e8534010-0a03-400b-9c35-ea3726bee297",
        "colab": {
          "referenced_widgets": [
            "bc17223bc16a451b96e3040d5f5ed3c2",
            "dcef699b355c4fc4b21cf713d0b2607e",
            "676948ced7734a4489de0111114d8325",
            "296525fdab90420c9617853f8b2af6e5"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc17223bc16a451b96e3040d5f5ed3c2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "dcef699b355c4fc4b21cf713d0b2607e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "676948ced7734a4489de0111114d8325"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "296525fdab90420c9617853f8b2af6e5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids_train, attention_mask_train = tokenize_data(train_data['Utterance'].values, tokenizer)\n",
        "input_ids_dev, attention_mask_dev = tokenize_data(dev_data['Utterance'].values, tokenizer)\n",
        "input_ids_test, attention_mask_test = tokenize_data(test_data['Utterance'].values, tokenizer)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:10:26.640728Z",
          "iopub.execute_input": "2024-04-26T14:10:26.641415Z",
          "iopub.status.idle": "2024-04-26T14:10:29.893285Z",
          "shell.execute_reply.started": "2024-04-26T14:10:26.641386Z",
          "shell.execute_reply": "2024-04-26T14:10:29.892503Z"
        },
        "trusted": true,
        "id": "-dWsRdC28aPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels_train = torch.tensor(train_data['Emotion'].values)\n",
        "labels_dev = torch.tensor(dev_data['Emotion'].values)\n",
        "labels_test = torch.tensor(test_data['Emotion'].values)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:10:41.839946Z",
          "iopub.execute_input": "2024-04-26T14:10:41.840673Z",
          "iopub.status.idle": "2024-04-26T14:10:41.860986Z",
          "shell.execute_reply.started": "2024-04-26T14:10:41.840643Z",
          "shell.execute_reply": "2024-04-26T14:10:41.860046Z"
        },
        "trusted": true,
        "id": "Qlyu2-zN8aPc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "dataset_train = TensorDataset(input_ids_train, attention_mask_train, labels_train)\n",
        "dataset_dev = TensorDataset(input_ids_dev, attention_mask_dev, labels_dev)\n",
        "dataset_test = TensorDataset(input_ids_test, attention_mask_test, labels_test)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:10:51.170839Z",
          "iopub.execute_input": "2024-04-26T14:10:51.171462Z",
          "iopub.status.idle": "2024-04-26T14:10:51.176773Z",
          "shell.execute_reply.started": "2024-04-26T14:10:51.171432Z",
          "shell.execute_reply": "2024-04-26T14:10:51.175908Z"
        },
        "trusted": true,
        "id": "-Hc48HAn8aPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=len(label_dict))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:11:00.508855Z",
          "iopub.execute_input": "2024-04-26T14:11:00.509457Z",
          "iopub.status.idle": "2024-04-26T14:11:01.806186Z",
          "shell.execute_reply.started": "2024-04-26T14:11:00.509427Z",
          "shell.execute_reply": "2024-04-26T14:11:01.805248Z"
        },
        "trusted": true,
        "id": "IWauGhIO8aPd",
        "outputId": "f704a18d-19de-40a6-82f8-35c139f97d3a",
        "colab": {
          "referenced_widgets": [
            "5ef87208cb15453aa457d030413f5474"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ef87208cb15453aa457d030413f5474"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 12,
          "output_type": "execute_result",
          "data": {
            "text/plain": "AlbertForSequenceClassification(\n  (albert): AlbertModel(\n    (embeddings): AlbertEmbeddings(\n      (word_embeddings): Embedding(30000, 128, padding_idx=0)\n      (position_embeddings): Embedding(512, 128)\n      (token_type_embeddings): Embedding(2, 128)\n      (LayerNorm): LayerNorm((128,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0, inplace=False)\n    )\n    (encoder): AlbertTransformer(\n      (embedding_hidden_mapping_in): Linear(in_features=128, out_features=768, bias=True)\n      (albert_layer_groups): ModuleList(\n        (0): AlbertLayerGroup(\n          (albert_layers): ModuleList(\n            (0): AlbertLayer(\n              (full_layer_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (attention): AlbertAttention(\n                (query): Linear(in_features=768, out_features=768, bias=True)\n                (key): Linear(in_features=768, out_features=768, bias=True)\n                (value): Linear(in_features=768, out_features=768, bias=True)\n                (attention_dropout): Dropout(p=0, inplace=False)\n                (output_dropout): Dropout(p=0, inplace=False)\n                (dense): Linear(in_features=768, out_features=768, bias=True)\n                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              )\n              (ffn): Linear(in_features=768, out_features=3072, bias=True)\n              (ffn_output): Linear(in_features=3072, out_features=768, bias=True)\n              (activation): NewGELUActivation()\n              (dropout): Dropout(p=0, inplace=False)\n            )\n          )\n        )\n      )\n    )\n    (pooler): Linear(in_features=768, out_features=768, bias=True)\n    (pooler_activation): Tanh()\n  )\n  (dropout): Dropout(p=0.1, inplace=False)\n  (classifier): Linear(in_features=768, out_features=7, bias=True)\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define training parameters\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=(0.1 * (len(dataset_train) // batch_size)), num_training_steps=len(dataset_train) * epochs)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:11:13.821544Z",
          "iopub.execute_input": "2024-04-26T14:11:13.821938Z",
          "iopub.status.idle": "2024-04-26T14:11:13.833817Z",
          "shell.execute_reply.started": "2024-04-26T14:11:13.821911Z",
          "shell.execute_reply": "2024-04-26T14:11:13.832878Z"
        },
        "trusted": true,
        "id": "kIRGGOwz8aPd",
        "outputId": "17789259-5994-4a21-b0f3-3dcf0ddaf6f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data loaders\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if torch.cuda.is_available() else {}\n",
        "dataloader_train = DataLoader(dataset_train, sampler=RandomSampler(dataset_train), batch_size=batch_size, **kwargs)\n",
        "dataloader_dev = DataLoader(dataset_dev, sampler=SequentialSampler(dataset_dev), batch_size=batch_size, **kwargs)\n",
        "dataloader_test = DataLoader(dataset_test, sampler=SequentialSampler(dataset_test), batch_size=len(test_data), **kwargs)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:11:43.843272Z",
          "iopub.execute_input": "2024-04-26T14:11:43.843643Z",
          "iopub.status.idle": "2024-04-26T14:11:43.85024Z",
          "shell.execute_reply.started": "2024-04-26T14:11:43.843615Z",
          "shell.execute_reply": "2024-04-26T14:11:43.849097Z"
        },
        "trusted": true,
        "id": "CCGm9gxi8aPe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
        "import torch\n",
        "\n",
        "# Training loop\n",
        "best_val_f1 = 0.0\n",
        "for epoch in range(1, epochs + 1):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for batch in dataloader_train:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "\n",
        "        model.zero_grad()\n",
        "        outputs = model(**inputs)\n",
        "        loss = outputs[0]\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    # Evaluate on validation set\n",
        "    model.eval()\n",
        "    predictions, true_labels = [], []\n",
        "\n",
        "    for batch in dataloader_dev:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        logits = outputs[1]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = inputs['labels'].cpu().numpy()\n",
        "\n",
        "        predictions.append(logits)\n",
        "        true_labels.append(label_ids)\n",
        "\n",
        "    predictions = np.concatenate(predictions, axis=0)\n",
        "    true_labels = np.concatenate(true_labels, axis=0)\n",
        "    val_f1 = f1_score(np.argmax(predictions, axis=1), true_labels, average='weighted')\n",
        "    print(f'Epoch {epoch} - Validation F1 Score: {val_f1}')\n",
        "\n",
        "    # Save the model if validation F1 score improves\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        torch.save(model.state_dict(), 'ALBERT_model.pth')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:17:40.688118Z",
          "iopub.execute_input": "2024-04-26T14:17:40.688829Z",
          "iopub.status.idle": "2024-04-26T14:22:44.171578Z",
          "shell.execute_reply.started": "2024-04-26T14:17:40.688784Z",
          "shell.execute_reply": "2024-04-26T14:22:44.170326Z"
        },
        "trusted": true,
        "id": "wowNfnp-8aPe",
        "outputId": "6d8bb451-0de1-435c-e9fa-430843c2a985"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Epoch 1 - Validation F1 Score: 0.6154549207518676\nEpoch 2 - Validation F1 Score: 0.616704868887906\nEpoch 3 - Validation F1 Score: 0.616704868887906\nEpoch 4 - Validation F1 Score: 0.5953134895503484\nEpoch 5 - Validation F1 Score: 0.5953134895503484\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the best model for evaluation on test set\n",
        "model.load_state_dict(torch.load('ALBERT_model.pth'))\n",
        "model.eval()\n",
        "\n",
        "# Evaluate on test set\n",
        "predictions, true_labels = [], []\n",
        "\n",
        "for batch in dataloader_test:\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    inputs = {'input_ids': batch[0], 'attention_mask': batch[1], 'labels': batch[2]}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    logits = outputs[1]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = inputs['labels'].cpu().numpy()\n",
        "\n",
        "    predictions.append(logits)\n",
        "    true_labels.append(label_ids)\n",
        "\n",
        "predictions = np.concatenate(predictions, axis=0)\n",
        "true_labels = np.concatenate(true_labels, axis=0)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:23:54.289064Z",
          "iopub.execute_input": "2024-04-26T14:23:54.289429Z",
          "iopub.status.idle": "2024-04-26T14:23:58.649748Z",
          "shell.execute_reply.started": "2024-04-26T14:23:54.2894Z",
          "shell.execute_reply": "2024-04-26T14:23:58.648555Z"
        },
        "trusted": true,
        "id": "wPvP6jxb8aPf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate additional evaluation metrics\n",
        "test_f1 = f1_score(np.argmax(predictions, axis=1), true_labels, average='weighted')\n",
        "test_accuracy = accuracy_score(np.argmax(predictions, axis=1), true_labels)\n",
        "conf_matrix = confusion_matrix(true_labels, np.argmax(predictions, axis=1))\n",
        "class_report = classification_report(true_labels, np.argmax(predictions, axis=1))\n",
        "\n",
        "print(f'Test F1 Score: {test_f1}')\n",
        "print(f'Test Accuracy: {test_accuracy}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix}')\n",
        "print(f'Classification Report:\\n{class_report}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:30:33.318394Z",
          "iopub.execute_input": "2024-04-26T14:30:33.31918Z",
          "iopub.status.idle": "2024-04-26T14:30:33.341722Z",
          "shell.execute_reply.started": "2024-04-26T14:30:33.319138Z",
          "shell.execute_reply": "2024-04-26T14:30:33.340762Z"
        },
        "trusted": true,
        "id": "1YQXCeHM8aPf",
        "outputId": "45a58d99-7f62-43f7-86d3-2dc219875005"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Test F1 Score: 0.6601915808718849\nTest Accuracy: 0.5467432950191571\nConfusion Matrix:\n[[1175    0    0    0   81    0    0]\n [ 122    0    0    0  159    0    0]\n [  29    0    0    0   21    0    0]\n [ 161    0    0    0   47    0    0]\n [ 150    0    0    0  252    0    0]\n [  43    0    0    0   25    0    0]\n [ 132    0    0    0  213    0    0]]\nClassification Report:\n              precision    recall  f1-score   support\n\n           0       0.65      0.94      0.77      1256\n           1       0.00      0.00      0.00       281\n           2       0.00      0.00      0.00        50\n           3       0.00      0.00      0.00       208\n           4       0.32      0.63      0.42       402\n           5       0.00      0.00      0.00        68\n           6       0.00      0.00      0.00       345\n\n    accuracy                           0.55      2610\n   macro avg       0.14      0.22      0.17      2610\nweighted avg       0.36      0.55      0.43      2610\n\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n  _warn_prf(average, modifier, msg_start, len(result))\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Define emotion labels\n",
        "emotion_labels = ['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust', 'anger']\n",
        "\n",
        "# Display model predictions for randomly selected samples\n",
        "num_samples = 5  # Number of samples to display\n",
        "sample_indices = random.sample(range(len(predictions)), num_samples)\n",
        "\n",
        "print(\"Randomly Selected Samples - Model Predictions vs. True Emotions:\")\n",
        "print(\"------------------------------------------------------------------\")\n",
        "for idx in sample_indices:\n",
        "    input_text = test_data['Utterance'].iloc[idx]\n",
        "    predicted_emotion = emotion_labels[np.argmax(predictions[idx])]\n",
        "    true_emotion = emotion_labels[true_labels[idx]]\n",
        "    confidence_score = predictions[idx][np.argmax(predictions[idx])]\n",
        "\n",
        "    print(f\"Sentence: {input_text}\")\n",
        "    print(f\"Predicted Emotion: {predicted_emotion} (Confidence: {confidence_score:.2f})\")\n",
        "    print(f\"True Emotion: {true_emotion}\")\n",
        "    print(\"------------------------------------------\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:40:35.023859Z",
          "iopub.execute_input": "2024-04-26T14:40:35.024533Z",
          "iopub.status.idle": "2024-04-26T14:40:35.032892Z",
          "shell.execute_reply.started": "2024-04-26T14:40:35.0245Z",
          "shell.execute_reply": "2024-04-26T14:40:35.031955Z"
        },
        "trusted": true,
        "id": "EMB2t4YP8aPf",
        "outputId": "f8072533-0f09-47ae-91c8-d650b1039575"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Randomly Selected Samples - Model Predictions vs. True Emotions:\n------------------------------------------------------------------\nSentence: Whoa!\nPredicted Emotion: joy (Confidence: 1.24)\nTrue Emotion: surprise\n------------------------------------------\nSentence: Weâ€™re just celebrating that Joey got his health insurance back.\nPredicted Emotion: neutral (Confidence: 2.10)\nTrue Emotion: joy\n------------------------------------------\nSentence: Yeah!\nPredicted Emotion: joy (Confidence: 1.24)\nTrue Emotion: joy\n------------------------------------------\nSentence: Okay, so you were trying to play bad this whole time.\nPredicted Emotion: neutral (Confidence: 2.10)\nTrue Emotion: surprise\n------------------------------------------\nSentence: I broke it.\nPredicted Emotion: neutral (Confidence: 2.12)\nTrue Emotion: sadness\n------------------------------------------\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader, TensorDataset, WeightedRandomSampler, SequentialSampler\n",
        "from transformers import AlbertTokenizer, AlbertForSequenceClassification, AdamW\n",
        "from sklearn.metrics import f1_score, accuracy_score, confusion_matrix, classification_report"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:55:38.827885Z",
          "iopub.execute_input": "2024-04-26T14:55:38.828674Z",
          "iopub.status.idle": "2024-04-26T14:55:38.833383Z",
          "shell.execute_reply.started": "2024-04-26T14:55:38.828647Z",
          "shell.execute_reply": "2024-04-26T14:55:38.832443Z"
        },
        "trusted": true,
        "id": "2LB1RsmW8aPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model\n",
        "model = AlbertForSequenceClassification.from_pretrained(\"albert-base-v2\", num_labels=len(label_dict))\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Define training parameters\n",
        "batch_size = 16\n",
        "epochs = 5\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5, eps=1e-8)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:57:13.882664Z",
          "iopub.execute_input": "2024-04-26T14:57:13.883546Z",
          "iopub.status.idle": "2024-04-26T14:57:14.158611Z",
          "shell.execute_reply.started": "2024-04-26T14:57:13.883513Z",
          "shell.execute_reply": "2024-04-26T14:57:14.1577Z"
        },
        "trusted": true,
        "id": "nK5CY9DZ8aPg",
        "outputId": "48429eea-e2f6-4523-aa4c-f63f4cb43c39"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "Some weights of AlbertForSequenceClassification were not initialized from the model checkpoint at albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute class weights for weighted loss\n",
        "class_weights = torch.tensor([1.0, 10.0, 20.0, 30.0, 1.0, 50.0, 10.0]).to(device)  # Adjust weights based on class importance\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T14:57:16.302166Z",
          "iopub.execute_input": "2024-04-26T14:57:16.302524Z",
          "iopub.status.idle": "2024-04-26T14:57:16.307818Z",
          "shell.execute_reply.started": "2024-04-26T14:57:16.302495Z",
          "shell.execute_reply": "2024-04-26T14:57:16.306837Z"
        },
        "trusted": true,
        "id": "B7bkOt4y8aPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-26T15:02:52.008913Z",
          "iopub.execute_input": "2024-04-26T15:02:52.0096Z"
        },
        "trusted": true,
        "id": "h0c5VfBE8aPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SVxoISg98aPh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}